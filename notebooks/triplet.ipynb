{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from skimage import transform\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../eval/identity_CelebA.txt') as file:\n",
    "    labels = []\n",
    "    fnames = []\n",
    "    for line in file:\n",
    "        fields = line.strip().split()\n",
    "        fnames.append(fields[0])\n",
    "        labels.append(int(fields[1]))\n",
    "    labels = np.array(labels)\n",
    "    fnames = np.array(fnames)\n",
    "f_ids = dict(zip(fnames, range(len(fnames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleBatchGen:\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.yvals = np.unique(y)\n",
    "        counts = Counter(y)\n",
    "        self.ybig = np.array([value for value, count in counts.items() if count > 2 * batch_size])\n",
    "        self.yids = dict()\n",
    "        for yval in self.yvals:\n",
    "            self.yids[yval] = np.where(y == yval)[0]\n",
    "        self.y_train, self.y_test = train_test_split(self.ybig, test_size=0.01, random_state=1234)\n",
    "        yset = set(self.y_train)\n",
    "        self.train_ids = np.array([idx for idx in range(len(self.y)) if self.y[idx] in yset])\n",
    "            \n",
    "    def generate_batches(self, n_batches):\n",
    "        for _ in range(n_batches):\n",
    "            an_label = np.random.choice(self.y_train)\n",
    "            np.random.shuffle(self.yids[an_label])\n",
    "            an_ids = self.yids[an_label][:self.batch_size]\n",
    "            pos_ids = self.yids[an_label][self.batch_size: 2 * self.batch_size]\n",
    "            neg_ids = self.train_ids[np.random.randint(0, len(self.train_ids), self.batch_size)]\n",
    "            while np.any(self.y[neg_ids] == an_label):\n",
    "                neg_ids = np.random.randint(0, len(self.y), self.batch_size)\n",
    "            yield self.X[an_ids], self.X[pos_ids], self.X[neg_ids]\n",
    "            \n",
    "    def test_batch(self):\n",
    "        an_label = np.random.choice(self.y_test)\n",
    "        np.random.shuffle(self.yids[an_label])\n",
    "        an_ids = self.yids[an_label][:self.batch_size]\n",
    "        pos_ids = self.yids[an_label][self.batch_size: 2 * self.batch_size]\n",
    "        neg_ids = self.train_ids[np.random.randint(0, len(self.train_ids), self.batch_size)]\n",
    "        return self.X[an_ids], self.X[pos_ids], self.X[neg_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = TripleBatchGen(fnames, labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ims(fnames, addr='../img_align_celeba/'):\n",
    "    ims = []\n",
    "    for fname in fnames:\n",
    "        ims.append(io.imread(addr + fname))\n",
    "    return np.stack(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_transform(X):\n",
    "    height = X.shape[1] \n",
    "    width = X.shape[2]\n",
    "    X_out = np.zeros((X.shape[0], height, width, 3), dtype=np.float32)\n",
    "    \n",
    "    for idx, x in enumerate(X):\n",
    "        x = transform.resize(x, (height, width))\n",
    "        angle = np.random.uniform(-10, 10)\n",
    "        h_scale = np.random.randint(0, 10)\n",
    "        v_scale = np.random.randint(0, 10)\n",
    "        h_pos = np.random.randint(0, h_scale + 1)\n",
    "        v_pos = np.random.randint(0, v_scale + 1)\n",
    "        x = transform.rotate(x, angle)\n",
    "        x = transform.resize(x, (height + v_scale, width + h_scale))\n",
    "        x = x[v_pos:height + v_pos, h_pos: width + h_pos]\n",
    "        X_out[idx] = x\n",
    "    X_out = X_out.transpose([0, 3, 1, 2])\n",
    "    return X_out\n",
    "\n",
    "def test_transform(X):\n",
    "    height = X.shape[1]\n",
    "    width = X.shape[2] \n",
    "    X_out = np.zeros((X.shape[0], height, width, 3), dtype=np.float32)\n",
    "    for idx, x in enumerate(X):\n",
    "        x = transform.resize(x, (height, width))\n",
    "        X_out[idx] = x\n",
    "    X_out = X_out.transpose([0, 3, 1, 2])\n",
    "    return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyVGG, self).__init__()\n",
    "        self.features = torchvision.models.squeezenet1_0(pretrained=False).features\n",
    "        #for par in self.features.parameters():\n",
    "        #    par.requires_grad=False\n",
    "        #15360\n",
    "        #66560\n",
    "        self.embeddings = nn.Sequential(nn.Linear(66560, 1024), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "                                        #nn.Linear(2048, 1024), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "                                        nn.Linear(1024, 128))\n",
    "        self.classif = nn.Sequential(self.embeddings, nn.ReLU(), nn.Linear(128, 40))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # print(x.shape)\n",
    "        return F.normalize(self.embeddings(x), dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.logstack = []\n",
    "        \n",
    "    def log(self, text):\n",
    "        self.logstack.append(text)\n",
    "        \n",
    "    def flush(self):\n",
    "\n",
    "        with open(self.filename, 'a') as f:\n",
    "            for text in self.logstack:\n",
    "                f.write(text + '\\n')\n",
    "        self.logstack = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = MyVGG().cuda()\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "# criterion = F.triplet_margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyVGG().cuda()\n",
    "net.load_state_dict(torch.load('model_tr'))\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = F.triplet_margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-c27a348c4e97>\", line 10, in <module>\n",
      "    x = ran_transform(load_ims(x))\n",
      "  File \"<ipython-input-6-c4f6d6942448>\", line 7, in ran_transform\n",
      "    x = transform.resize(x, (height, width))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 135, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py\", line 775, in warp\n",
      "    order=order, mode=mode, cval=cval))\n",
      "  File \"skimage/transform/_warps_cy.pyx\", line 131, in skimage.transform._warps_cy._warp_fast\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/core/numeric.py\", line 424, in asarray\n",
      "    def asarray(a, dtype=None, order=None):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 708, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "batch_size = batch_gen.batch_size\n",
    "epoch_size = 50\n",
    "n_epochs = 3000\n",
    "logger = Logger('logs2.txt')\n",
    "curloss = 100000\n",
    "for n in range(n_epochs):\n",
    "    net.train()\n",
    "    for b_id, (Xanc, Xpos, Xneg) in enumerate(batch_gen.generate_batches(epoch_size)):\n",
    "        x = np.concatenate((Xanc, Xpos, Xneg))\n",
    "        x = ran_transform(load_ims(x))\n",
    "        x = Variable(torch.FloatTensor(x).cuda())\n",
    "        optimizer.zero_grad()\n",
    "        out = net(x)\n",
    "        loss = criterion(out[:batch_size], out[batch_size: 2 * batch_size], out[2 * batch_size:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossv = loss.data.cpu().numpy()[0]\n",
    "        logger.log(' '.join(['train', str(epoch), str(b_id), str(lossv)]))\n",
    "    net.eval()\n",
    "    Xanc, Xpos, Xneg = batch_gen.test_batch()\n",
    "    x = np.concatenate((Xanc, Xpos, Xneg))\n",
    "    x = test_transform(load_ims(x))\n",
    "    x = Variable(torch.FloatTensor(x).cuda())\n",
    "    out = net(x)\n",
    "    loss = criterion(out[:batch_size], out[batch_size: 2 * batch_size], out[2 * batch_size:])\n",
    "    lossv = loss.data.cpu().numpy()[0]\n",
    "    logger.log(' '.join(['test', str(epoch), str(lossv)]))\n",
    "    if lossv < curloss:\n",
    "        curloss = lossv\n",
    "        torch.save(net.state_dict(), 'model_tr')\n",
    "    epoch += 1\n",
    "    logger.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model_tr1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
